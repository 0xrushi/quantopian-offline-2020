{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "import cvxpy as cp\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from scipy.optimize import minimize\n",
    "from pandas_datareader import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_asset_kit as mla\n",
    "sys.path.append(\"../\")\n",
    "import edhec_risk_kit as erk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using seaborn style (type plt.style.available to see available styles)\n",
    "plt.style.use(\"seaborn-dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief summary of week 1 (questions and home points)\n",
    "\n",
    "## Introduction to Machine Learning\n",
    "\n",
    "**QUESTION: What distinguishes supervised learning from unsupervised learning? Multiple responses possible.**\n",
    "1. Supervised learning requires labeled data to properly classify objects, whereas unsupervised learning identifies interesting patterns in data – without label\n",
    "2. Most successful applications of machine learning have occurred in supervised learning\n",
    "3. Supervised learning requires a human to watch over the algorithm to be sure that it’s  working properly.\n",
    "\n",
    "**ANSWER: 1,2.** Supervised learning includes classification such as identifying the name of a song or the numbers on a handwritten zip-code. The success of these schemes depends upon several items: a large set of labeled data. I call this amount of data needed for a successful application: *adequate data*. Second, in most cases, there is the need for a type of stability. \n",
    "For example, we assume that the zip-code IDs remains the digits 0-9. \n",
    "\n",
    "Over the past decade, most successes in machine learning have occurred in the area of supervised learning (mostly classification). More recently, there have been breakthroughs in games such as Chess, Shogi, and Go, whereby the DeepMind team \n",
    "at Google in London have created the world best software for these problem. This domain fits under **reinforcement learning**.\n",
    "\n",
    "**QUESTION: What are the main differences between traditional statistical methods and modern non-parametric methods? Multiple responses possible.**\n",
    "1. Few assumptions needed for non-parametric methods\n",
    "2. Traditional statistical methods rely on assumptions such as normal distributions for the random variables\n",
    "3. Traditional statistics depend upon massive data\n",
    "\n",
    "**ANSWER: 1,2**. The area of classical statistical analysis grew up with a host of assumptions. The most obvious ones occur \n",
    "in linear regression: linearity of explanatory and outcome variables, additivity, and relative independence \n",
    "of the explanatory variables. Massive research took place in the 1950s and 1960s to overcome some of these assumptions, \n",
    "such as adding nonlinear transformations, and addressing other loss functions such as absolute value |L1|.  \n",
    "These extensions had a minor impact on practice, partially due to the focus on theoretical properties of the techniques. \n",
    "Recall the long list of tests to *prove* statistical significance. The area of non-parametric methods began with \n",
    "the emergence of data collection at much higher frequency and across domains. These techniques led to modern \n",
    "machine learning algorithms and improved testing methodologies. In addition, statisticians (and other data scientists) \n",
    "began to recognize that stochastic optimization plays a critical role in the success of machine learning. \n",
    "In particular, increased computational capability, merged with large data and incentives for improving classification, \n",
    "has resulted in practical successes. These successes have surprised many expert observers over the past decade. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Applications\n",
    "\n",
    "**QUESTION: What are a few future applications of the FinTech revolution?**\n",
    "1. Robo-advisors will replace human investment advisors\n",
    "2. FinTech promises to bring loans and mortgages to individuals without long approval periods\n",
    "3. Machine learning algorithms will find the best performing stock and thereby eliminate investment professional\n",
    "4. Machine learning will be able to decide upon the best home location to satisfy our needs\n",
    "\n",
    "**ANSWER: 2**. The use of machine learning to issue bonds and mortgages is confirmed by reference to the efforts by \n",
    "Ant Financial in China – the MyBank app. Here, loans are issues with any formal support from the \n",
    "Ant Financial team and without reference to the massive amounts of research in this domain.\n",
    "\n",
    "Some HOME POINTS:\n",
    "- Financial Applications are often more complex than direct classification, e.g., due to privacy and ethical issues \n",
    "- Machine Learning algorithms can be difficult to interpret \n",
    "- Feature selection very important "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "**QUESTION: Which of the following are successful applications of supervised learning? Multiple responses possible.**\n",
    "1. Identify objects in front of an auto or truck\n",
    "2. Computer driven loans for individuals\n",
    "3. Fraud detection for credit cards\n",
    "\n",
    "**ANSWER: all of them.** The successes in supervised learning are arriving at an accelerating rate. Outside of finance,  we can readily identify the name of a song by an app listening to a few bars, or we can give a name to a \n",
    "bird or tree without fail. Likewise, zip-codes are read by automated supervised learning algorithms, \n",
    "at a lower error rate than humans. Visual object identification has gained in accuracy as well, and \n",
    "these classification algorithms are a critical element in automated vehicles. \n",
    "In the area of finance and banking, FinTech firms such as Ant Financial are able to issue \n",
    "loans by means of machine learning, without the need for traditional bankers or brick and mortar \n",
    "bank branches. And fraud detection has been improved. **There is still much to be done in the domain of decision making under uncertainty.**\n",
    "\n",
    "\n",
    "**QUESTION: What are the primary assumptions of supervised learning? Multiple responses possible.**\n",
    "1. There is adequate data possessing labels\n",
    "2. The underlying application has stability so that the data is representative\n",
    "3. The labels indicate correct classification\n",
    "4. The classification problem requires linearity\n",
    "\n",
    "**ANSWER: 1,2,3**. The nature of supervised learning requires data with the correct classification, called labels. \n",
    "The amount of data must be “adequate” so that the machine learning algorithm is able to identify \n",
    "the characteristics for future out-of-sample evaluation. \n",
    "In addition, there must be enough stability over time. \n",
    "\n",
    "Some HOME POINTS:\n",
    "- Machine Learning operates on a large number of features. Perhaps more systematic than humans. \n",
    "- Humans apply intuition and vast experience. \n",
    "- Computers apply multiple algorithms with a large number of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First algorithms\n",
    "**QUESTION: How does the train-and-test approach improve accuracy? Multiple responses possible**\n",
    "1. Provides out-of-sample evidence and thereby reduces overfitting\n",
    "2. Allows for evaluation of performance ex post\n",
    "3. Refines the information content of historical data\n",
    "\n",
    "**ANSWER: 1,3**. Traditional statistical methods rely on a large number of assumptions in order to provide \n",
    "evidence of good statistical properties. On the other hand, machine learning algorithms \n",
    "render fewer assumptions than traditional methods, and thereby there is a greater need \n",
    "for out-of-sample analysis. The train-and-test approach, in conjunction with cross validation, fits this philosophy. \n",
    "\n",
    "Some HOME POINTS:\n",
    "- Adequate data must be available so that results can be generalised.\n",
    "- Data must relatively stable, changes in the data cannot occur at high frequency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights of best practice and challenges ahead\n",
    "**QUESTION: What is the motivation for employing an ensemble forecasting framework?**\n",
    "1. The forecasting problem can be posed as a linear regression model\n",
    "2. The application requires linearity\n",
    "3. Ensemble forecasts are superior to a single forecasting model when the aggregation of weak classifiers is better than the forecast of a single strong classifier\n",
    "\n",
    "**ANSWER: 3**. There are many examples in which an ensemble forecast is more reliable than the forecast \n",
    "from a single model.  An example is the forecast of recessions in the U.S. over the last 20 years. \n",
    "The Blue Chip economists projections were better able to forecast a recession than the \n",
    "leading econometric forecasting system\n",
    "\n",
    "**QUESTION: What are the advantages of the train-and-test procedures? Multiple responses possible.**\n",
    "1. Helps evaluate the model’s capability via out of sample testing\n",
    "2. Reduces the chances of overfitting\n",
    "3. Provides a full proof approach for classification\n",
    "4. Indicates readiness for decision making\n",
    "\n",
    "**ANSWER: 1,2**. The traditional statistical methods such as linear regression and econometrics made a \n",
    "number of assumptions about model structure and employed as much historical data as possible. \n",
    "Machine learning, on the other hand, employs the data without many assumptions about \n",
    "model structure. This approach requires much more data than earlier methods, but it \n",
    "provides more reliable algorithms for classification in many situations.\n",
    "The train-and-test procedures are employed to calculate the (hyper-parameters) of a model \n",
    "via out-of-sample data and to reduce the chances of overfitting.  As we have mentioned, \n",
    "a model that fits the data perfectly in-sample is often unable to do well with out of sample data. \n",
    "Thus, the train-and-test procedure is helpful in reducing overfitting. \n",
    "\n",
    "\n",
    "\n",
    "**QUESTION: What are potential and actual successes of reinforcement learning? Multiple responses possible**\n",
    "1. The most powerful game playing systems in the world for chess, shogi, and go (AlphaZero)\n",
    "2. Automated medical diagnosis and treatment\n",
    "3. Online poker playing and associated betting strategies\n",
    "4. Identifying products for customers on the Amazon website\n",
    "\n",
    "**ANSWER: 1,3,4**. The area of reinforcement learning has gained much credibility and renown since the fast and \n",
    "powerful successes of the DeepMind team at Google with their software systems that \n",
    "created the world’s most powerful systems for playing chess, shogi, and go. This remarkable \n",
    "system requires no domain specific information about the game.  Instead, it simply “watches” \n",
    "each of these gains over a carefully curated set of experiments.  \n",
    "The product selection problem has similar characteristics in terms of its potential application \n",
    "of reinforcement learning. However, this area is much less structured that zero-sum games. \n",
    "And accordingly, there is controversy about the degree of success of **reinforcement learning**.\n",
    "\n",
    "\n",
    "Some HOME POINTS:\n",
    "- Train and test process\n",
    "- Ensamble models: combine a set of weak classifier into a strong classifier (boosting); then take the average of classifiers (**Wisdom of the crowd**) -> more robust classification \n",
    "- Shrinkage methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 2\n",
    "\n",
    "Below we briefly recall **factor models** (**see week 1 and week 2 of course 2**).\n",
    "\n",
    "## Factor models\n",
    "A **factor** is a variable that influences the **returns of assets**. It represents a **commonality** \n",
    "in the returns, i.e., something outside the individual asset, and normally, **an exposure to some factor risk** over the long run **yields a reward** (the risk premium).\n",
    "\n",
    "In general, a **(multi)-factor model** with $K$ factors states that the \n",
    "**excessive return** of an asset $i$ satisfies:\n",
    "$$\n",
    "r_i^e := r_{i,t} - r_{f,t}  = \\alpha_i + \\beta_1^i f^{e}_1 +\\dots +\\beta_K^i f^{e}_K + \\varepsilon_{i,t}, \n",
    "$$\n",
    "where $\\{\\beta_j^i\\}_{j=1,\\dots,K}$ and $\\alpha_i$ are some real coefficients to be estimated, $\\varepsilon_{i,t}$ are idiosyncratic (uncorrelated) errors, and $\\{f_j\\}_{i=j,\\dots,K}$ are the **factor premia** which are the **returns that we get in exchange for exposing ourselves to the factors** (in particular $f^{e}_j$ denotes the excess return of the factor). \n",
    "\n",
    "We will call the betas coefficients as the **factor loadings**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Single Factor model\n",
    "We recall that the simplest factor model is the Sharpe's single-factor **Market Model** in which the only factor used is the excess return of the market $f^e_t = r_{m,t} - r_{f,t}$:\n",
    "$$\n",
    "r_i^e := r_{i,t} - r_{f,t} = \\alpha_i + \\beta^i (r_{m,t} - r_{f,t}) + \\varepsilon_{i,t}.\n",
    "$$\n",
    "In particular we recall that the **Capital Asset Pricing Model (CAPM)** is the model that predicts $\\alpha_i=0$:\n",
    "$$\n",
    "r_i^e := r_{i,t} - r_{f,t} = \\beta^i (r_{m,t} - r_{f,t}) + \\varepsilon_{i,t},\n",
    "$$\n",
    "and in which:\n",
    "$$\n",
    "\\beta_i := \\frac{\\text{Cov}(r_i,r_m)}{\\text{Var}(r_m)},\n",
    "$$\n",
    "denotes the sensitivity of the asset with respect to the market.\n",
    "\n",
    "\n",
    "In the risk analysis, we notice that when using the CAPM, we can obtain an expression for the variance of the return of asset $i$ in terms of the variance of the market. That is, if we take tha variance on both sides of the equation above:\n",
    "$$\n",
    "(\\sigma_i^e)^2 = \\beta_i^2 (\\sigma_m^e)^2 + \\sigma^2_{\\varepsilon_i},\n",
    "$$\n",
    "and this allows us to classify the risk between **systematic risk $(\\sigma_m^e)$** \n",
    "on the one hand and **specific risks $\\sigma_{\\varepsilon_i}$** on the other hand.\n",
    "\n",
    "Furthermore, we can alos define the $R^2$ metrics defined as:\n",
    "$$\n",
    "R^2 := \\frac{ \\beta_i^2 (\\sigma_m^e)^2 }{(\\sigma_i^e)^2}, \n",
    "$$\n",
    "which is **the part of the variance explained by the factor**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fama-French Model\n",
    "\n",
    "The **Fama-French model** is a **three-factor** model which enhance the CAPM (one-factor model). The three factors are:\n",
    "- **Market Factor**: the market risk (i.e., as in the CAPM),\n",
    "- **Size Factor**: the outperformance of **small versus big** companies,\n",
    "- **Value Factor**: the outperformance of **high book/market versus small book/market** companies.\n",
    "\n",
    "What Fama and French did was to take the entire universe of stocks an put them into ten buckets (**deciles**). They sorted such deciles in two ways. \n",
    "\n",
    "A first sorting was done according to the **size**, i.e., the **market capitalization**, \n",
    "and then they compared the performance of the bottom $10\\%$ companies versus the top $10\\%$ companies according to the size.\n",
    "\n",
    "The second sorting was done according to the **book-to-market ratios** (B/P ratio), and then they did the same, i.e., they looked at \n",
    "the performance of the bottom $10\\%$ companies (Growth Stocks) versus the top $10\\%$ companies (Value Stocks). \n",
    "\n",
    "Fama and French observed that the classes of stocks that have tended to do better than the market as a whole have been \n",
    "(i) the **small caps** (bottom decile w.r.t sizes) and (ii) the **Value Stocks** (top decile w.r.t. B/P ratios). \n",
    "Hence, they introduced the **size factor** and the **value factor** in addition to the **market factor** \n",
    "of simple CAPM and enhance the model ($1993$): \n",
    "$$\n",
    "\\mathbb{E}[r_i] - r_f = \n",
    "\\beta_{i,\\text{MKT}}\\mathbb{E}[r_m - r_f] + \\beta_{i,\\text{SMB}}\\mathbb{E}[\\text{SMB}] + \\beta_{i,\\text{HMS}}\\mathbb{E}[\\text{HMS}],   \n",
    "$$\n",
    "where:\n",
    "- $\\beta_{i,\\text{MKT}}$ is the same $\\beta$ of the CAPM (we stress the dependence on the **market**), \n",
    "- $\\text{SMB}$ means **Small (Size) Minus Big (Size)** stocks, \n",
    "- $\\text{HML}$ means **High (B/P ratio) Minus Low (B/P ratio)** stocks.\n",
    "\n",
    "It is remarkable the fact that **high book-to-price stocks (i.e., Value stocks)**, **small-cap**, and **past winners** stocks \n",
    "have been found to earn a higher return (that is, they have been found to outperform **low book-to-price (Growth)**, **large-cap**, and \n",
    "**past losers** stocks, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Factors\n",
    "In addition to **market**, **value** and **size** factors, the **Momentum Factor** has been also very often used as a meaningful, explanatory variable to try and explain differences in expected return. \n",
    "\n",
    "The **Momentum factor** is defined as the **difference in performance between the past winners and the past losers**. In particular, the momentum can be seen as an attribute of the asset. \n",
    "We can think about the asset, on a given sample period, as being a past winner or a past loser and this would tend to explain some persistence in performance because past winners tend to outperform past losers. \n",
    "\n",
    "Literature has also looked at other factors, including the **Low Volatility factor**, distinguishing the low volatility assets from the high volatility assets. In this case, we found that **low volatility assets tend to outperform high volatility assets** even though they are less risky. \n",
    "\n",
    "There is also a **Liquidity Factor**. Less liquid assets tend to have a higher risk premia associated to them compared to higher liquidity stocks, as expected. \n",
    "\n",
    "Another last factor can be the **Quality Factor**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions on factors \n",
    "\n",
    "Let us consider tha case of a simple two-factors model ($K=2$): \n",
    "$$\n",
    "r_i^e := r_i - r_f =  \\beta_1^i f_1 + \\beta_2^i f_2 + \\varepsilon_i\n",
    "\\quad \\forall\\;i=1,\\dots,N.\n",
    "$$\n",
    "\n",
    "Now, the variance of the asset's excess return is given by, for all $i$: \n",
    "$$\n",
    "c_{ii}^2 = (\\sigma_i^e)^2 := \\text{Var}\\left(\\beta_1^i f_1 + \\beta_2^i f_2 + \\varepsilon_i\\right) \n",
    "= (\\beta_1^i)^2 \\sigma_{f_1}^2 + (\\beta_2^i)^2 \\sigma_{f_2}^2 + 2\\beta_1^i \\beta_2^i\\text{Cov}(f_1,f_2) + \\sigma_{\\varepsilon_i}^2, \n",
    "$$\n",
    "where we have assumed that the **covariances between factors and errors are zero**. \n",
    "\n",
    "The covariances are then:\n",
    "$$\n",
    "c_{ij} = \\text{Cov}\\left(r_i^e,r_j^e\\right) \n",
    "= \\text{Cov}\\left(\\beta_1^i f_1 + \\beta_2^i f_2 + \\varepsilon_i, \\beta_1^j f_1 + \\beta_2^j f_2 + \\varepsilon_j\\right)\n",
    "= \\beta_1^i \\beta_1^j \\sigma_{f_1}^2 \n",
    "+ \\beta_2^i \\beta_2^j \\sigma_{f_2}^2 \n",
    "+ \\left(\\beta_1^i \\beta_2^j + \\beta_2^i \\beta_1^j\\right) \\text{Cov}(f_1,f_2) + \\text{Cov}(\\varepsilon_i,\\varepsilon_j).\n",
    "$$\n",
    "\n",
    "In a general multi-factor model (with $K$ factors), the variances and covariances are then given by:\n",
    "\\begin{align}\n",
    "c_{ii}^2 &= \\sum_{k=1}^K \\beta_k^i\\sigma_{f_k}^2 + \\sum_{k\\neq n}\\beta_k^i\\beta_n^i \\text{Cov}(f_k,f_n) + \\sigma_{\\varepsilon_i}^2, \\\\\n",
    "c_{ij}   &= \\sum_{k=1}^K \\beta_k^i\\beta_k^j\\sigma_{f_k}^2 + \\sum_{k\\neq n} \\beta_k^i\\beta_n^j \\text{Cov}(f_k,f_n)  \n",
    "+ \\text{Cov}(\\varepsilon_i,\\varepsilon_j) \n",
    "\\quad\\text{for $i\\neq j$}.\n",
    "\\end{align}\n",
    "\n",
    "Now, two things that we should try to do are (i) try to **look for uncorrelated factors**, i.e., $\\text{Cov}(f_k,f_n)=0$, for $k\\neq n$,  \n",
    "and (ii) assume that **errors are uncorrelated**, i.e., $\\text{Cov}(\\varepsilon_i,\\varepsilon_j)=0$, for $i\\neq j$. \n",
    "If a few factors can completely capture the cross-sectional risks, the number of parameters in covariance matrix estimation can be significantly reduced. In particular, the equations above are simplified:\n",
    "\\begin{align}\n",
    "c_{ii}^2 &= \\sum_{k=1}^K \\beta_k^i\\sigma_{f_k}^2  + \\sigma_{\\varepsilon_i}^2, \\\\\n",
    "c_{ij}   &= \\sum_{k=1}^K \\beta_k^i\\beta_k^j\\sigma_{f_k}^2\n",
    "\\quad\\text{for $i\\neq j$}.\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression and Penalty Methods\n",
    "When using a factor model, all is about estimating parameters betas and alphas. \n",
    "Normally, we can conduct **traditional regressions**, where we minimize some error between the return of the asset that we are \n",
    "looking at and the loadings of the factors on that asset.\n",
    "\n",
    "### Classic Least-Squared fit (Ordinary Least-Squared OLS)\n",
    "\n",
    "In this context, we have a $n\\times 1$ vector $\\mathbf{y}$ which is the excess return of the asset under consideration and a $n\\times K$ \n",
    "matrix $X$ which represent our data, i.e., the excess return of the $K$ factors we have chosen. Hence we have to minimize:\n",
    "$$\n",
    "\\text{minimize} \\;\\; \\frac{1}{2N}||\\mathbf{y} - X\\mathbf{\\beta}||_2^2 = \n",
    "\\frac{1}{2N}\\sum_{i=1}^n \\left(y_i  - X_i\\cdot\\mathbf{\\beta}  \\right)^2, \n",
    "$$\n",
    "where $\\mathbf{\\beta}=(\\beta_1,\\dots,\\beta_K, \\alpha)^T$ is the vector of betas and the intercept alpha coefficients, \n",
    "and $X_i$ denotes the $i$-th row of the matrix $X$. \n",
    "The betas give us the best solution fitting of the assets to a linear relationship between the explanatory variables (the factors) \n",
    "and the dependent variable (the return of the asset). \n",
    "\n",
    "For such a minimization problem we can find the analytical expression for coefficients betas and alpha. The solution is given by \n",
    "$$\n",
    "\\beta^{\\text{OLS}} = (X^T X)^{-1} X^T \\mathbf{y}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty method: Ridge methods ($L^2$ penalization)\n",
    "\n",
    "Traditional regression methods are enhanced and made more robust by addign **penalty terms**. In particular, betas values would be much too high or low if the expalantory variables (the factors) had moderate-to-hight correlation. \n",
    "\n",
    "Then we can modify the minimization problem above by adding an extra term which at the end of the day simply \n",
    "**shrinks the optimal betas values**:\n",
    "$$\n",
    "\\text{minimize} \\;\\; \\frac{1}{2N} \\bigl( ||\\mathbf{y} - X\\mathbf{\\beta}||^2_2 + \\lambda||\\beta||_2^2  \\bigr)\n",
    "$$\n",
    "which is equivalent on solving the classic least-squared fit problem with a constraint on the betas coefficients. This method is called **$L^2$ penalization method or Ridge regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty method: Lasso methods ($L^1$ penalization)\n",
    "\n",
    "A second modification to the first minimization problem is adding an extra term which, as in the Ridge regression, \n",
    "simply **shrinks the optimal betas values** and increase sparsity of the coefficient:\n",
    "$$\n",
    "\\text{minimize} \\;\\; \\frac{1}{2N} \\bigl( ||\\mathbf{y} - X\\mathbf{\\beta} ||_2^2 + \\lambda||\\beta||_1  \\bigr)\n",
    "$$\n",
    "which is equivalent on solving the classic least-squared fit problem with a constraint on the betas coefficients. This method is called **$L^1$ penalization method or Lasso regression**.\n",
    "\n",
    "Lasso regression results in a sparser solution than Ridge regression (i.e., fewer coefficients with non-zero values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty method: Elastic Net\n",
    "\n",
    "A third modification of the first minimization problem is putting together both the Lasso and the Ridge penalizations, i.e., we add \n",
    "adding two extra terms for shrinking the optimal betas values and increase sparsity of the coefficient:\n",
    "$$\n",
    "\\text{minimize} \\;\\; \\frac{1}{2N} \\bigl( ||\\mathbf{y} - X\\mathbf{\\beta} ||_2^2 + \\lambda_1||\\beta||_1 + \\lambda_2||\\beta||^2_2  \\bigr).\n",
    "$$\n",
    "This method is called the **Elastic Net regression**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Subset Regression \n",
    "\n",
    "Penalized regressions are not the only type of regression we can run. We can also run constrained regressions. \n",
    "Formally, we define an intuitive constrained regression called the **Best Subset Regression** which attempts to find the linear model subject to the constraint that only $x$ factor loadings can be nonzero (in this case, $x$ is an integer that the user defines).\n",
    "\n",
    "The best subset regression is defined as follows. \n",
    "Let $L$ be the number of variables considered, i.e., the explanatory variables of the model (the factors) and let $N$ be the maximum number of variables allowed in the subset. \n",
    "Also let $\\textbf{z}$ be a $L\\times 1$ vector of **binary variables** and let $M$ be a very \n",
    "large number. \n",
    "Then: \n",
    "\\begin{equation*} \n",
    "    {\\hat{\\beta}}^{\\text{Best Subset}} = \\text{argmin}\\left\\{ ||\\mathbf{y} - X\\mathbf{\\beta} ||_2^2 \\right\\}\n",
    "\\end{equation*}\n",
    "subject to:\n",
    "\\begin{cases}\n",
    "\\sum_{i=1}^{L} z_i &\\leq N,  \\\\\n",
    "Mz + \\beta & \\geq 0,         \\\\\n",
    "\\beta  &\\leq Mz,             \\\\\n",
    "\\text{$\\mathbf{z}$ is binary}\n",
    "\\end{cases}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "The **Cross validation** is a Machine Learning approach for calculating the parameter in a statistical estimation task. \n",
    "Rather than fitting a model to all of the available data, **the approach “sets aside” subsets of the data for a validation phase** and repeat the process a certain number of times (e.g. 10 times). Then it averages the results obtained.\n",
    "\n",
    "For the purpose of factor investing, we add a penalty term to shrink the beta estimates, the factor loadings in the regression model \n",
    "(e.g., by using Ridge or Lasso regression). In addition, we add a penalty parameter that determines the best degree of shrinkage. \n",
    "This hyper parameter is calculated by identifying the value with the lowest out-of-sample error. \n",
    "Thus, **cross validation reduces the chances of overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of 5-factor models \n",
    "\n",
    "In the following example, we are interested in explaining the asset returns with a **five-factor model**:\n",
    "- **World Equity**: this factor represents worldwide equity returns.\n",
    "- **US Treasury**: this factor contains returns from treasury bonds in United States, the bonds with the least risk.\n",
    "- **Bond Risk Premia**: this is a credit factor that captures extra yield from risky bonds. It is defined as the spread between high risk bonds and US Treasury bonds.\n",
    "- **Inflation Protection**: this is a *style* factor that considers the difference between real and nominal returns, thus balances the need for both.\n",
    "- **Currency Protection**: this is also a *style* factor that includes risk premia for US domestic assets.\n",
    "\n",
    "We have the data for the above factors and for the following set of assets:\n",
    "- **US Equities**:\n",
    "- **Real Estate**:\n",
    "- **Commodities**:\n",
    "- **Corp Bonds**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Regime-5</th>\n",
       "      <th>Regime-7</th>\n",
       "      <th>US Equities</th>\n",
       "      <th>Real Estate</th>\n",
       "      <th>Commodities</th>\n",
       "      <th>Corp Bonds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1985-01</th>\n",
       "      <td>0.028511</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>-0.016265</td>\n",
       "      <td>0.030292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.056605</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>0.048963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-02</th>\n",
       "      <td>-0.009204</td>\n",
       "      <td>-0.044692</td>\n",
       "      <td>0.057381</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>-0.015217</td>\n",
       "      <td>-0.042029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-03</th>\n",
       "      <td>0.075134</td>\n",
       "      <td>0.028719</td>\n",
       "      <td>-0.024396</td>\n",
       "      <td>-0.002848</td>\n",
       "      <td>-0.020739</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007299</td>\n",
       "      <td>-0.006716</td>\n",
       "      <td>0.037171</td>\n",
       "      <td>0.032666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-04</th>\n",
       "      <td>-0.002459</td>\n",
       "      <td>0.023084</td>\n",
       "      <td>-0.004869</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.012255</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>-0.035116</td>\n",
       "      <td>0.037125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-05</th>\n",
       "      <td>0.040245</td>\n",
       "      <td>0.086780</td>\n",
       "      <td>-0.044417</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>-0.002219</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.027241</td>\n",
       "      <td>0.004351</td>\n",
       "      <td>0.104199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         World Equities  US Treasuries  Bond Risk Premium  \\\n",
       "Date                                                        \n",
       "1985-01        0.028511       0.031500           0.006408   \n",
       "1985-02       -0.009204      -0.044692           0.057381   \n",
       "1985-03        0.075134       0.028719          -0.024396   \n",
       "1985-04       -0.002459       0.023084          -0.004869   \n",
       "1985-05        0.040245       0.086780          -0.044417   \n",
       "\n",
       "         Inflation Protection  Currency Protection  Regime-5  Regime-7  \\\n",
       "Date                                                                     \n",
       "1985-01             -0.016265             0.030292         1         1   \n",
       "1985-02              0.006362             0.010258         1         1   \n",
       "1985-03             -0.002848            -0.020739         1         1   \n",
       "1985-04              0.003089             0.008187         1         1   \n",
       "1985-05              0.004077            -0.002219         1         1   \n",
       "\n",
       "         US Equities  Real Estate  Commodities  Corp Bonds  \n",
       "Date                                                        \n",
       "1985-01     0.081301     0.056605     0.021351    0.048963  \n",
       "1985-02     0.030075     0.016448    -0.015217   -0.042029  \n",
       "1985-03    -0.007299    -0.006716     0.037171    0.032666  \n",
       "1985-04    -0.012255     0.000906    -0.035116    0.037125  \n",
       "1985-05     0.064516     0.027241     0.004351    0.104199  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors_assets = mla.get_factors_and_assets()\n",
    "factor_names   = list( factors_assets.columns[:5] )\n",
    "asset_names    = list( factors_assets.columns[7:] )\n",
    "factors_assets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fs = [\"Real Estate\",\"Commodities\"]\n",
    "erk.compound_returns(factors_assets[fs], start=1).plot(grid=True, figsize=(8,5), logy=True, title=\"Total returns of assets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose Real Estate as the dependent variable and using the 5 factors as explanatory variables\n",
    "factors = factors_assets[factor_names].values\n",
    "assets  = factors_assets[asset_names].values\n",
    "y = factors_assets[\"Real Estate\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.310261</td>\n",
       "      <td>1.212508</td>\n",
       "      <td>1.054238</td>\n",
       "      <td>0.287919</td>\n",
       "      <td>0.36184</td>\n",
       "      <td>-0.003587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.310261       1.212508           1.054238              0.287919   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta              0.36184 -0.003587  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression (OLS) using analytical formula\n",
    "factors_ones = np.concatenate( (factors, np.ones((factors.shape[0],1))), axis=1 )\n",
    "betas = np.linalg.inv( factors_ones.T.dot(factors_ones) ).dot( factors_ones.T ).dot( y )\n",
    "betas = mla.display_betas(betas, factor_names) \n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.310261</td>\n",
       "      <td>1.212508</td>\n",
       "      <td>1.054238</td>\n",
       "      <td>0.287919</td>\n",
       "      <td>0.36184</td>\n",
       "      <td>-0.003587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.310261       1.212508           1.054238              0.287919   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta              0.36184 -0.003587  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression (OLS) using statsmodels OLS method implemented in our kit\n",
    "lm = erk.linear_regression(y, factors)\n",
    "betas = mla.display_betas(lm.params, factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, they coincide. We can also use the method **linear_regression_sk** which uses **scikit-learn** library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.310261</td>\n",
       "      <td>1.212508</td>\n",
       "      <td>1.054238</td>\n",
       "      <td>0.287919</td>\n",
       "      <td>0.36184</td>\n",
       "      <td>-0.003587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.310261       1.212508           1.054238              0.287919   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta              0.36184 -0.003587  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = mla.linear_regression_sk(y, factors)\n",
    "betas = mla.display_betas( np.append(lm.coef_, lm.intercept_), factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Drawbacks \n",
    "\n",
    "OLS has major drawbacks. First, OLS has **no mechanism to filter out noise variables**. Second, it assumes that **factor loadings are constant over time**. In practice, you will generally have many variables that you would like to filter down.  Moreover, the assumption that the factor loadings are constant over time is restrictive, and not true.  In fact, we will show that factor loadings are highly dependent on the time period.\n",
    "\n",
    "To demonstrate how OLS can be susceptible to noise, we introduce **a noise variable positively correlated with the World Equities factor**. \n",
    "Then we re-run the OLS regression and we will see that the regression chosses to average the two signals, \n",
    "changing the loading on the World Equity factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_plus_noise = factors_assets[factor_names].copy()\n",
    "factors_plus_noise_names = factor_names + [\"Noise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = factors_assets.shape[0]\n",
    "noise = np.random.normal(loc=0, scale=2*factors_assets[\"World Equities\"].std(), size=ndata)\n",
    "noise = np.reshape( noise + factors_assets[\"World Equities\"].values, (ndata,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_plus_noise[\"Noise\"] = noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.308896</td>\n",
       "      <td>1.212651</td>\n",
       "      <td>1.054312</td>\n",
       "      <td>0.28735</td>\n",
       "      <td>0.361935</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>-0.003585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.308896       1.212651           1.054312               0.28735   \n",
       "\n",
       "      Currency Protection     Noise     alpha  \n",
       "beta             0.361935  0.001284 -0.003585  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = mla.linear_regression_sk(y, factors_plus_noise)\n",
    "betas = mla.display_betas( np.append(lm.coef_, lm.intercept_), factors_plus_noise_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate on the drawback of the OLS regression we show that **the OLS estimator depends greatly on the time period**. \n",
    "We pick different time periods and run the OLS regression and see that the factor loadings can change dramatically \n",
    "depending on the time period. \n",
    "\n",
    "We filter the data into two different regimes: a first **normal regime** will be months where US Equities had a positive monthly return and a second **crash regime** being the months where US Equities had a negative return. \n",
    "These are crude approximations, but even with this crude definition we will return substantially different factor loadings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.15022</td>\n",
       "      <td>1.30286</td>\n",
       "      <td>1.100558</td>\n",
       "      <td>0.210193</td>\n",
       "      <td>0.05183</td>\n",
       "      <td>0.00348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta         0.15022        1.30286           1.100558              0.210193   \n",
       "\n",
       "      Currency Protection    alpha  \n",
       "beta              0.05183  0.00348  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering data for positive US Equities - normal regime \n",
    "normal_data = factors_assets[factors_assets[\"US Equities\"] > 0].copy()\n",
    "normal_factors = normal_data[factor_names]\n",
    "normal_y = normal_data[asset_names][\"Real Estate\"]\n",
    "\n",
    "lm = mla.linear_regression_sk(normal_y, normal_factors)\n",
    "betas = mla.display_betas( np.append(lm.coef_, lm.intercept_), factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.365824</td>\n",
       "      <td>0.959781</td>\n",
       "      <td>0.792532</td>\n",
       "      <td>0.540801</td>\n",
       "      <td>0.588727</td>\n",
       "      <td>-0.011274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.365824       0.959781           0.792532              0.540801   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta             0.588727 -0.011274  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering data for negative US Equities - crash regime \n",
    "crash_data = factors_assets[factors_assets[\"US Equities\"] <= 0].copy()\n",
    "crash_factors = crash_data[factor_names]\n",
    "crash_y = crash_data[asset_names][\"Real Estate\"]\n",
    "\n",
    "lm = mla.linear_regression_sk(crash_y, crash_factors)\n",
    "betas = mla.display_betas( np.append(lm.coef_, lm.intercept_), factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a crude definition of a **crash regime** we have isolated different factor loadings. \n",
    "Notice that during normal periods the loading on Currency Protection is close to zero, but during crash periods is **10x** larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For penalty methods, $\\lambda$ is an hyperparameter that we need to choose. Now, **scikit-learn does not use $\\lambda$**. It rather \n",
    "uses the parameter $\\alpha$ which can be related to $\\lambda$ via the following equation:\n",
    "$$\n",
    "\\alpha = \\frac{\\lambda}{2 n},\n",
    "$$\n",
    "where $n$ is the number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.349738</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>0.574002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.349738         0.5422           0.574002                   0.0   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta                  0.0  0.001834  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for now let's arbitrarily pick lambda = 0.1\n",
    "lambdapar = 0.1\n",
    "lm = mla.lasso_regression_sk(y, factors, lambdapar=lambdapar)\n",
    "betas = mla.display_betas( np.append(lm.coef_, lm.intercept_), factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show how the Lasso regression filters out the noise variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.346528</td>\n",
       "      <td>0.542612</td>\n",
       "      <td>0.574044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00302</td>\n",
       "      <td>0.001838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.346528       0.542612           0.574044                   0.0   \n",
       "\n",
       "      Currency Protection    Noise     alpha  \n",
       "beta                  0.0  0.00302  0.001838  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = mla.lasso_regression_sk(y, factors_plus_noise, lambdapar=lambdapar)\n",
    "betas = mla.display_betas( np.append(lm.coef_, lm.intercept_), factors_plus_noise_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.405948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.005355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.405948            0.0            0.12743                   0.0   \n",
       "\n",
       "      Currency Protection     Noise     alpha  \n",
       "beta                  0.0  0.002316  0.005355  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another try with lambda = 0.2\n",
    "lm = mla.lasso_regression_sk(y, factors_plus_noise, lambdapar=0.2)\n",
    "betas = mla.display_betas( np.append(lm.coef_, lm.intercept_), factors_plus_noise_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "In the experiments above with Lasso regression we had indeed another problem, the choice of $\\lambda$. \n",
    "In practice, most people use **cross-validation** to find out an optimal value. \n",
    "We will not give a formal definition of cross-validation here, and instead we will give a heuristic.\n",
    "\n",
    "In **cross-validation**, we first break the training set into $K$ folds, and define a list of $\\lambda$ values. \n",
    "For each fold, and for each $\\lambda$, we train the model $k-1$ other folds, and calculate the error on the test fold. At the end of this, you will have $K$ out of sample errors for each value of lambda. Then we pick the $\\lambda$ which produces the average error across \n",
    "the out of sample tests.\n",
    "\n",
    "Here we use cross validation to pick the optimal lambda value for Lasso regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "gsCV = mla.cross_val_lasso_regression(y, factors, lambda_max=0.25, n_lambdas=100, n_folds=10, rs=7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lambda: 0.048634343434343426\n"
     ]
    }
   ],
   "source": [
    "best_lambda = mla.recover_regression_bestpar_from_gsCV(gsCV, factors, \"lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.875641</td>\n",
       "      <td>0.835079</td>\n",
       "      <td>0.044825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.311805       0.875641           0.835079              0.044825   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta                  0.0 -0.000342  "
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression using the best estimator\n",
    "betas = np.append(gsCV.best_estimator_.coef_, gsCV.best_estimator_.intercept_)\n",
    "betas = mla.display_betas(betas, factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run the cross-validation Lasso regression in the case of noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "gsCV = mla.cross_val_lasso_regression(y, factors_plus_noise, lambda_max=0.25, n_lambdas=100, n_folds=10, rs=7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lambda: 0.048634343434343426\n"
     ]
    }
   ],
   "source": [
    "best_lambda = mla.recover_regression_bestpar_from_gsCV(gsCV, factors_plus_noise, \"lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.30852</td>\n",
       "      <td>0.875974</td>\n",
       "      <td>0.83526</td>\n",
       "      <td>0.043452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>-0.000336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta         0.30852       0.875974            0.83526              0.043452   \n",
       "\n",
       "      Currency Protection     Noise     alpha  \n",
       "beta                  0.0  0.003075 -0.000336  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression using the best estimator\n",
    "betas = np.append(gsCV.best_estimator_.coef_, gsCV.best_estimator_.intercept_)\n",
    "betas = mla.display_betas(betas, factors_plus_noise_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall that the **Elastic Net regression** was: \n",
    "$$\n",
    "\\text{minimize} \\;\\; \\frac{1}{2N} \\bigl( ||\\mathbf{y} - X\\mathbf{\\beta} ||_2^2 + \\lambda_1||\\beta||_1 + \\lambda_2||\\beta||^2_2  \\bigr).\n",
    "$$\n",
    "However, the **ElasticNet** method implemented in scikit-learn defines the parameters $\\lambda_1$ and $\\lambda_2$ as:\n",
    "$$\n",
    "\\lambda_1 := \\alpha L^1_{ratio}\n",
    "\\quad\\text{and}\\quad\n",
    "\\lambda_2 := \\frac{1}{2}\\alpha \\left(1-L^1_{ratio}\\right),\n",
    "$$\n",
    "where $L^1_{ratio} \\in [0,1]$ for which if $L^1_{ratio}=1$ we are doing Lasso regression (hence, $\\alpha$ here is defined as the parameter in the Lasso regression) and when $L^1_{ratio}=0$ we do a Ridge Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "gsCV = mla.cross_val_elasticnet_regression(y, factors, lambda_max=0.25, n_lambdas=50, l1_ratio_max=0.99, n_l1ratio=50, n_folds=10, rs=7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lambda1: 0.04611379591836734\n",
      "best lambda2: 0.00023289795918367363\n"
     ]
    }
   ],
   "source": [
    "best_lambda1, best_lambda2 = mla.recover_regression_bestpar_from_gsCV(gsCV, factors, \"elasticnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.310548</td>\n",
       "      <td>0.889796</td>\n",
       "      <td>0.844634</td>\n",
       "      <td>0.056504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.310548       0.889796           0.844634              0.056504   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta                  0.0 -0.000444  "
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression using the best estimator\n",
    "betas = np.append(gsCV.best_estimator_.coef_, gsCV.best_estimator_.intercept_)\n",
    "betas = mla.display_betas(betas, factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# The case with noise \n",
    "gsCV = mla.cross_val_elasticnet_regression(y, factors_plus_noise, lambda_max=0.25, n_lambdas=50, l1_ratio_max=0.99, n_l1ratio=50, n_folds=10, rs=7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lambda1: 0.04611379591836734\n",
      "best lambda2: 0.00023289795918367363\n"
     ]
    }
   ],
   "source": [
    "best_lambda1, best_lambda2 = mla.recover_regression_bestpar_from_gsCV(gsCV, factors_plus_noise, \"elasticnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.307373</td>\n",
       "      <td>0.890116</td>\n",
       "      <td>0.844807</td>\n",
       "      <td>0.055179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>-0.000439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.307373       0.890116           0.844807              0.055179   \n",
       "\n",
       "      Currency Protection     Noise     alpha  \n",
       "beta                  0.0  0.002974 -0.000439  "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression using the best estimator\n",
    "betas = np.append(gsCV.best_estimator_.coef_, gsCV.best_estimator_.intercept_)\n",
    "betas = mla.display_betas(betas, factors_plus_noise_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Best Subset Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.453734</td>\n",
       "      <td>1.395798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta             0.0       1.453734           1.395798                   0.0   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta                  0.0 -0.001956  "
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using max_vars = 2\n",
    "betas, alpha = mla.best_subset_regression(y, factors, max_vars=2)\n",
    "\n",
    "# Regression using the best estimator\n",
    "betas = np.append(betas, alpha)\n",
    "betas = mla.display_betas(betas, factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.274697</td>\n",
       "      <td>1.186262</td>\n",
       "      <td>1.091385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.274697       1.186262           1.091385                   0.0   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta                  0.0 -0.002295  "
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using max_vars = 3\n",
    "betas, alpha = mla.best_subset_regression(y, factors, max_vars=3)\n",
    "\n",
    "# Regression using the best estimator\n",
    "betas = np.append(betas, alpha)\n",
    "betas = mla.display_betas(betas, factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.274692</td>\n",
       "      <td>1.186272</td>\n",
       "      <td>1.091393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.274692       1.186272           1.091393                   0.0   \n",
       "\n",
       "      Currency Protection  Noise     alpha  \n",
       "beta                  0.0    0.0 -0.002295  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using max_vars = 3 and noisy data\n",
    "betas, alpha = mla.best_subset_regression(y, factors_plus_noise, max_vars=3)\n",
    "\n",
    "# Regression using the best estimator\n",
    "betas = np.append(betas, alpha)\n",
    "betas = mla.display_betas(betas, factors_plus_noise_names)\n",
    "betas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
